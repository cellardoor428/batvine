{
 "metadata": {
  "name": "night_sum_2011"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Import everything\n",
      "import numpy as np\n",
      "import pandas as p\n",
      "import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Load the batid classified file\n",
      "table = p.read_csv('../data/pass_bin_2011.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here are the column names - note that the case is the same as the csv\n",
      "table.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "Index([path, folder, pass, ncalls, qual, ANPA, EPFU, MYEV, MYTH, LANO,\n",
        "       LACI, MYCA, LABL, PAHE, MYLU, MYVO, TABR, MYYU, COTO, EUPE], dtype=object)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check out ANPA data (or any other column)\n",
      "table['ANPA']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "0     1\n",
        "1     0\n",
        "2     0\n",
        "3     0\n",
        "4     0\n",
        "5     0\n",
        "6     0\n",
        "7     0\n",
        "8     0\n",
        "9     0\n",
        "10    0\n",
        "11    0\n",
        "12    1\n",
        "13    1\n",
        "14    1\n",
        "...\n",
        "11825    0\n",
        "11826    0\n",
        "11827    0\n",
        "11828    0\n",
        "11829    0\n",
        "11830    0\n",
        "11831    0\n",
        "11832    0\n",
        "11833    0\n",
        "11834    0\n",
        "11835    0\n",
        "11836    0\n",
        "11837    0\n",
        "11838    0\n",
        "11839    0\n",
        "Name: ANPA, Length: 11840"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make the columns for date and detector_date\n",
      "# We will correct for nightly turnover, so date = starting night\n",
      "\n",
      "pass_col = table['pass']\n",
      "\n",
      "# Set up empty lists to hold columns for date and detector_date\n",
      "date_col = []\n",
      "detector_date_col = []\n",
      "\n",
      "# Loop through all passes in pass_col\n",
      "for tpass in pass_col.values:\n",
      "\n",
      "    # Split this pass into words, 0th word is detector, 2nd word is date\n",
      "    tpass_split = tpass.split('_')\n",
      "    tdetect = tpass_split[0]\n",
      "    \n",
      "    # Adjust date\n",
      "    ttime = tpass_split[3]  # Get time as a string\n",
      "    tdate = tpass_split[2]  # Get date as a string\n",
      "    \n",
      "    if int(ttime) < 120000:  # If it's before noon, correct tdate\n",
      "        \n",
      "        # Pull out year, month, date from tdate and make all int's\n",
      "        tyear = int(tdate[:4])\n",
      "        tmonth = int(tdate[4:6])\n",
      "        tday = int(tdate[6:])\n",
      "        \n",
      "        # Fix the date by subtracting one day\n",
      "        tdate_wrong_datetime = datetime.date(tyear, tmonth, tday)\n",
      "        one_day = datetime.timedelta(1)\n",
      "        tdate_right_datetime = tdate_wrong_datetime - one_day\n",
      "        \n",
      "        # Get the string back in the right format\n",
      "        tdate_right_string_dash = datetime.date.isoformat(tdate_right_datetime)\n",
      "        tdate = tdate_right_string_dash.replace('-','')\n",
      "    \n",
      "    # Add tdate and tdetector_tdate to appropriate cols\n",
      "    date_col.append(tdate)\n",
      "    detector_date_col.append(tdetect + '_' + tdate)\n",
      "\n",
      "print pass_col[0:20]  # Do a quick visual check\n",
      "print date_col[0:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0     SM1_0_20110714_213435_531.00#\n",
        "1     SM1_0_20110714_230150_383.00#\n",
        "2     SM1_0_20110715_014037_778.00#\n",
        "3     SM1_0_20110715_031757_145.00#\n",
        "4     SM1_0_20110715_033949_246.00#\n",
        "5     SM1_0_20110715_041736_261.00#\n",
        "6     SM1_0_20110715_042513_363.00#\n",
        "7     SM1_0_20110715_042521_100.00#\n",
        "8     SM1_0_20110715_043452_357.00#\n",
        "9     SM1_0_20110715_044329_142.00#\n",
        "10    SM1_0_20110715_051543_476.00#\n",
        "11    SM1_0_20110715_051551_400.00#\n",
        "12    SM1_0_20110715_212424_694.00#\n",
        "13    SM1_0_20110715_214228_761.00#\n",
        "14    SM1_0_20110715_215304_460.00#\n",
        "15    SM1_0_20110715_220140_332.00#\n",
        "16    SM1_0_20110715_223704_746.00#\n",
        "17    SM1_0_20110715_225242_904.00#\n",
        "18    SM1_0_20110716_001756_228.00#\n",
        "19    SM1_0_20110716_003614_374.00#\n",
        "Name: pass\n",
        "['20110714', '20110714', '20110714', '20110714', '20110714', '20110714', '20110714', '20110714', '20110714', '20110714', '20110714', '20110714', '20110715', '20110715', '20110715', '20110715', '20110715', '20110715', '20110715', '20110715']"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Adding a column to a data frame is easy\n",
      "table.insert(3, 'date', date_col)\n",
      "table.insert(4, 'detector_date', detector_date_col)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table.columns  # Check that they're added"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "Index([path, folder, pass, date, detector_date, ncalls, qual, ANPA, EPFU,\n",
        "       MYEV, MYTH, LANO, LACI, MYCA, LABL, PAHE, MYLU, MYVO, TABR, MYYU,\n",
        "       COTO, EUPE], dtype=object)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Save csv with these extra cols to cross check visually\n",
      "table.to_csv('../results/pass_bin_detector_date.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Group rows according to the column detector_date\n",
      "# This makes a grouped data frame object that isn't easy to visualize\n",
      "# But then we can aggregate with the sum function, and see the result\n",
      "# This will throw away all non-numeric colums (they can't be added)\n",
      "# See http://pandas.pydata.org/pandas-docs/dev/groupby.html\n",
      "\n",
      "gtable = table.groupby('detector_date').sum().reset_index()\n",
      "print gtable.columns\n",
      "\n",
      "# Add a column for total number of passes, while we're here\n",
      "# Note that this requires 3 columns be present before the bat call columns\n",
      "tota_col = []\n",
      "for i in range(len(gtable['detector_date'])):\n",
      "    tota_col.append(np.sum(gtable.values[i][3:]))  # Total trial and error\n",
      "\n",
      "gtable['TOTA'] = tota_col\n",
      "    \n",
      "# Save result\n",
      "gtable.to_csv('../results/pass_bin_nightly_sums.csv', index=False)\n",
      "\n",
      "# Check the csv for accuracy - looks good!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "array([detector_date, ncalls, qual, ANPA, EPFU, MYEV, MYTH, LANO, LACI,\n",
        "       MYCA, LABL, PAHE, MYLU, MYVO, TABR, MYYU, COTO, EUPE], dtype=object)"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Now, we know that the detector_date is our 'atomic unit' of data (for now)\n",
      "# So each row in ntable is a data point, and we need to add some variables\n",
      "# that we can use to analyze what factors drive changes in bat abundance.\n",
      "# Let's start by adding site, using a join with the key detector_date\n",
      "# (This is the table that Rochelle is creating now, but we'll use a sample.)\n",
      "# Then, we can use site as a key and use join to get some other variables.\n",
      "# (This is the second table that we'll need.)\n",
      "# For now, we can just use some sample tables in the data folder.\n",
      "\n",
      "# Note that the sample tables are incomplete, and values they don't contain\n",
      "# will have NA.\n",
      "\n",
      "# Load the two sample tables\n",
      "dd_site_table = p.read_csv('../data/detector_date_to_site_samp.csv')\n",
      "site_var_table = p.read_csv('../data/site_to_variables_samp.csv')\n",
      "\n",
      "# Take gtable and join first dd_site_table on the key detector_date\n",
      "# ... then site_var_table on the key site\n",
      "join1 = p.merge(gtable, dd_site_table, on='detector_date', how='left')\n",
      "join2 = p.merge(join1, site_var_table, on='site', how='left')\n",
      "\n",
      "# Save the doubly-joined table\n",
      "join2.to_csv('../results/pass_bin_nightly_sums_full.csv')\n",
      "\n",
      "# Joins are a bit conceptually difficult - have a look at this page\n",
      "# http://pandas.pydata.org/pandas-docs/dev/merging.html#database-style-dataframe-joining-merging\n",
      "# But still might require some explanation first - we can discuss\n",
      "# But suffice to say, it works!\n",
      "# If you can generate full tables like the two _samp tables in data, we'll be in business."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Adding site, using a join with the key detector_date\n",
      "\n",
      "# Loading the site & detector_date to site tables\n",
      "dd_site_table = p.read_csv('../data/detector_date_site_2011.csv')\n",
      "site_var_table = p.read_csv('../data/site_to_variables.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Double check the columns\n",
      "dd_site_table.columns\n",
      "site_var_table.columns[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "Index([site, extra, pair, lat, long, Vine05km, Vine10km, Vine15km,\n",
        "       Vine20km, Vine25km, Vine30km, Vine35km, Vine40km, Vine45km,\n",
        "       Vine50km, Vine55km, Vine60km, Hab05km, Hab10km, Hab15km], dtype=object)"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dd_site_table.columns # why didn't it print when I executed the above command?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "Index([detector_date, site], dtype=object)"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Take gtable and join first dd_site_table on the key detector_date\n",
      "#...then site_var_table on the key site\n",
      "join1 = p.merge(gtable, dd_site_table, on='detector_date', how='left')\n",
      "join2 = p.merge(join1, site_var_table, on='site', how='left')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Add column for date\n",
      "join2_dd_col = join2['detector_date']\n",
      "rdate_col = []\n",
      "# loop through detector_date column and pull out date\n",
      "for i in join2_dd_col.values:\n",
      "    dd_split = i.split('_')\n",
      "    rdate_col.append(dd_split[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#insert date column into join2 table\n",
      "join2.insert(3, 'date', rdate_col)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Save the double-joined table\n",
      "join2.to_csv('../results/pass_bin_2011_nightly_sums_full.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    }
   ],
   "metadata": {}
  }
 ]
}